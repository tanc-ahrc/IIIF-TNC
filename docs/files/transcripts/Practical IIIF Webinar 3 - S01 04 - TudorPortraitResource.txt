Sure, I can format the text into paragraphs for you without changing any of the words. Here's the formatted text:

Good afternoon everybody, and so I'm going to be presenting with Peter on the Tudor paintings, research project and repository pilot and to. So I'm from the National Portrait Gallery and my role in the tours national Collection project would be very much from the curatorial, non technical specialist perspective, and so the sort of end user point.

We had at the National Portrait Gallery from the result of a long-standing research project, a large number of images of Tudor paintings that we've been working in, collaboration with the Yale Center for British Art and the Paul, Mellon studies in British arts. And this was something we really wanted to begin to explore through. And kind of possibilities that are blank might open up this large data sets that we hold, and through the course of project we were able to work with Peter so ill pass on to him.

Hey, good afternoon so just a couple of background data futures is German not for profit? It's funded by some partner organizations, mainly European and US institutions. And we are the community lead for IIIF and also for OC FL in the invenio RDM consortium. RDM is the. Technology platform for for zenodo. Developed initially by CERN and RDM is a consortium we've put together over the last four years, which now has about 17 or 18 institutional contributors.

The next one. Umm? So there's a very simple. Presentation really we had talked with Joseph and subsequently with with Charlotte. About a year ago, a little more than a year ago, and we agreed to build. A repository using what then was the in development invenioRDM. It was at version four, it's just about to come out at version 9. And we were interested in the coherent set of images of Tudor portraits they had.

Because one of the things on our road map was to actually implement. The Mirador IIIF viewer in webpack, so that it was using a native IIIF. service within the repository, and this is just a quick narrative of how how that happened.

So during May we we talked about the corpus we were going to use. And I think almost 31st we got a data set from from Charlotte and in the subsequent weeks we used an infrastructure that we've we've had in place for. I don't know ten years or so. Which is Mongo DB based. To do accession of those images and metadata in the form of a spreadsheet, there are some screenshots in a minute.

Using this this freizo platform and that enabled us to produce a workflow for Charlotte to subsequently do metadata enrichment. And. In the short term, that infrastructure had orchid authentications that was not open to the public, it was really for for research purposes. So within a couple of weeks we had built a digital collection of the images with data site flavoured metadata in invenioRDM is basically data site.

And you've got to make all sorts of decisions about what is going to be a custom data type and what's going to be cast into true data type elements. And then the week after we were able to automatically generate an invenioRDM repository and a different IIIF service native to give the repository instance. Which in the short term had also orchid access, so you couldn't get in unless you gave it some orchid and your orchid was on a white list.

And this pretty much completed by the end of of June, and there was subsequent discussion about the visual design. The look and feel and getting released from the National Portrait Gallery to launch this service publicly. And that finally happened in. I think it was September. 

Last year was if Charlotte, you know. So, so they're within. Pretty much a month from signing an agreement and having the basic terms of what was to be made available publicly to having it available for review and subsequent launch. Basically one person month. And.

I guess the things to underline are that the invenioRDM platform is the ongoing technology base and CERN has already started reimplementing zenodo using that. So that's the G7 authorized Global catch-all repository for research data.

So really, what we've been able to demonstrate here is that infrastructure that had large scale contribution over many years from multiple countries and multiple funding sources. Not least, the European Commission's Open air program. Has provided a pretty gentle on-ramp for heritage data and we've got a couple of examples showing what's happening in other fields, which allow things like annotation, production of WADM, preservable, annotation metadata. And also longer-term OCL archives.

Perhaps if we could just look at the diagram. So, this breaks down into 3 simple steps which kind of mirror what I just said. We start with image files and basic metadata. Using Mongo we create a temporary digital collection which allows us to organize metadata and form it into a more data site friendly structure. That's good.

A separate IIIF service is not really intended for public consumption and in point of fact, having now launched the INVENIORDM, we can destroy all of the freizo investment because it was really just an on-ramp to organize the data. But freizo allowed us to generate IIIF services and to actually produce the invenio RDM repository at scale without having to create gazillion assets individually.

And what you get with that is long-term support of the repository for public access. It's got a whole bunch of stuff that you really don't want to implement on an institutional basis such as protocol for mass data harvesting. It's got a large support community. As I said, we're just at RDM released nine and probably we should get through 11 by the end of this year. And one of the new functions coming down the pipe is that we can now produce OCL archives that scale, basically snapshot the repository into an archived file which can live on tape. Nearline fetch me a dark archive. And which concentrates on version. So if there's ongoing contribution and metadata development within the repository, we can occasionally snapshot that to a format that can live on media that has a much lower cost barrier and individual cartridges such as LTO tapes only need to be renewed every 30 years or so.

So just look at the last slide. So this is just for me to have a moment to say about joys of metadata. Everybody contributing that from sort of my end of the project. That's very much that first moment where you present your meditative great kind of proudly and it's actually a complete mess of mix. No logic. So that kind of refining process. But then there was this opportunity to had kind of enhancements fixes. So actually, you know the volume of information and the range of information we could get was brilliant. It just took that sort of two-step process and need to make sure the kind of consistency. Language, and so we settled on because we were thinking of it as a pilot of 16 works from the galleries collection, for which we had a whole range of images from kind of a hero. Master image to snapshots of paintings in their frames. X Ray, IR UV and so just to kind of give that breadth. And so that was the sort of sample range that we did. 

Back to your. No, I mean this is completely. Whether where the work was actually done so the previous slide was a view of the initial metadata, wasn't it?

Charlotte? I think that might be might be enhanced one with the about this portrait information, yeah? But that was actually further enriched within within frizzo and actually subsequently within Invenio itself.

So here we're seeing the on-ramp, the accession of Charlotte's data. This is the Mongo DB interface and if we go on. Yeah. So this is just one of the records. And you can see at the top of the previous screen you can view it in Mirador, but you can also edit the metadata interactively and there are search facets on the left, rather like Invenio. All this, the Freizo thing predates Invenio by some years.

Next one. So this is. Mirador 3 IN webpack within the repository. And this is open to the public. And the current agreement is for there to be support of this pilot for five years. And really, we've done the heavy lifting is just a handful of assets in there, but this is infrastructure that. It's identical to the. It's an older platform, so this. We'll operate at scale. We've got other Invenio corpus repositories with millions of records in the same way. That's an order has.

The next one, so his. The detailed view within Invenio of one of the records. And I guess it's also worth saying that you can use. The mayoral view full screen. So you could actually have multiple views of different records side by side. And you'll see that this is familiar from Joseph's presentation because it's the same Harvard, Stanford Mirador development and just add that through the report's perspective.

So this was all sort of new world for us that we're not kind of that we're at the beginning of our IIIF journey and using it in certain kind of on-site access moments. We've had certain sort of embedded storytelling methods in our and on our website, but this sort of collections based moment to all those kind of internal conversations about about access and releasing things to the world and Creative Commons licenses. And so this was a really great kind of test project and worked with the group.

So future plans, yeah, so I mean we probably overused our time, but but this is really straightforward so. The immediate plan is for there to be five years of support of the repository itself, and obviously we can extend that. Umm? We will produce an OCL from this when we get on to the next release of Invenio and that will go to a distributed LTO. Tape library. But I think perhaps you could say a couple of words Charlottes about the potential for annotation and adding additional records. We've talked about across institutional whole bank corpus with the National Gallery.

Yes, so the kind of annotation question and this was something that perhaps has been sort of addressed by secretly that between the different as as Invenio has moved on and so now as an example of the Voltaire project, and we've got the image here that has built-in annotation options, so it's been again, as I say from a list of non-technical side astonishing to see over the course of a year that we're working with in 1009, and what was being constructed, and that is now part of it, but can now go on.

Do you have any other things that are widely available, so annotation is absolutely something we can now do with the Tudor images? An example here of the kind of photomicrograph map would be able to do, and then the other sort of future plan and kind of stumbling block in the broader questions of the kind of towards national collection that we had.

The sort of conversation conversations about how we might run a test of cross-collection repositories. These are working with the National Gallery that you just had a great sort of case study. Example of our sort of shared a whole band group, but it sort of fell at the institutional hurdle rather than necessarily the technical hurdle of the permissions to be able to work together. So, you know, conversations to continue with it in the future, but an example that I think many people listening will be familiar with in a position where addressing the technical questions of the national collection. But there's also the institutional questions.

And I think that's it. Thank you very much. Thank you. Thank you very much. There's one question at the moment in the question and answers. Where are you able to virtually layer the different images? Stroke information relating to the same portrait? So that's just a question to the relation to the choice of how the viewer was implemented, I expect.

Do you want me to? Yeah, totally. So this only implemented Mirador 3 and webpack. As I said, you can turn on the functionality to juxtapose multiple images of the same object, including other instruments in webpack to be able to do this within the repository could certainly be done. But I think another observation is that having done this, we've also now got a reference IIIF service.

Umm? For these objects, I mean, we just mentioned annotation in passing, and there's not really time to talk about it here. But Voltaire is a project using a much more recent workflow, and there are certainly 1000 or so annotations. We've got other corporate repositories with 800,000 annotations, but you have to begin to take care for those annotations to be referenced against known and long-term guaranteed resources. 

So I think this is a larger discussion. Clearly, you could support overlaying of instruments. Sorry, overlaying of different views of a record, but you would need other instruments to achieve that. And perhaps something to pick up in the conversation afterwards, but Tom, am I right?

Leaking memories of a conversation about scaling images, that was something you had thought about, which is part of the question of overlaying images that you've been working on at one point on scaling options. Yeah, there is an article about that somewhere. I don't know if Joe can dig out the link and stick it in there, but yeah, how do we deal with things that are different sizes when all our trip live image services make everything the same size? 
